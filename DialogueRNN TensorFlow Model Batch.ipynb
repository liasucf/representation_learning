{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff6862ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import torch.nn as nn\n",
    "import numpy as np, pickle, time, argparse\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, classification_report, precision_recall_fscore_support\n",
    "\n",
    "import tensorflow as tf\n",
    "import contractions\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import time\n",
    "import tensorflow.keras as k\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb9a26ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"deal with contracted texts\"\n",
    "def expand_text(text):\n",
    "    expanded_words = []\n",
    "    text = text.encode('utf-8').decode('cp1252').replace(\"Â’\", \"'\")\n",
    "    #text = text.replace(\"’\", \"'\")\n",
    "    for word in text.split():\n",
    "      # using contractions.fix to expand the shotened words\n",
    "      expanded_words.append(contractions.fix(word))   \n",
    "\n",
    "    expanded_text = ' '.join(expanded_words)\n",
    "    return expanded_text\n",
    "\n",
    "\n",
    "\n",
    "\"clean dataset\"\n",
    "def preprocess_text(x):\n",
    "    for punct in '\"!&?.,}-/<>#$%\\()*+:;=?@[\\\\]^_`|\\~':\n",
    "        x = x.replace(punct, ' ')\n",
    "    x = ' '.join(x.split())\n",
    "    x = x.lower()\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def create_utterances(filename, split):\n",
    "    sentences, emotion_labels, speakers, conv_id, = [], [], [], []\n",
    "    \n",
    "    lengths = []\n",
    "    with open(filename, 'r', encoding='latin1') as f:\n",
    "        a = json.load(f)\n",
    "        for c_id, line in enumerate(a):\n",
    "            for item in line:\n",
    "                sentences.append(item['utterance'])\n",
    "                emotion_labels.append(item['emotion'])\n",
    "                conv_id.append(split[:2] + '_c' + str(c_id))\n",
    "                speakers.append(item['speaker'])\n",
    "            \n",
    "            # u_id += 1\n",
    "                \n",
    "    data = pd.DataFrame(sentences, columns=['sentence'])\n",
    "    data['sentence'] = data['sentence'].apply(lambda x: expand_text(x))\n",
    "    data['sentence'] = data['sentence'].apply(lambda x: preprocess_text(x))\n",
    "\n",
    "    data['emotion_label'] = emotion_labels\n",
    "    data['speaker'] = speakers\n",
    "    data['conv_id'] = conv_id\n",
    "\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a4e267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe model, this can take some time...\n",
      "Completed loading pretrained GloVe model.\n",
      "Done. Completed preprocessing.\n"
     ]
    }
   ],
   "source": [
    "\"create embedding\"\n",
    "def load_pretrained_glove():\n",
    "    print(\"Loading GloVe model, this can take some time...\")\n",
    "    glv_vector = {}\n",
    "    f = open('glove.840B.300d.txt', encoding='utf-8')\n",
    "\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        try:\n",
    "            coefs = np.asarray(values[1:], dtype='float')\n",
    "            glv_vector[word] = coefs\n",
    "        except ValueError:\n",
    "            continue\n",
    "    f.close()\n",
    "    print(\"Completed loading pretrained GloVe model.\")\n",
    "    return glv_vector\n",
    "\n",
    "def encode_labels(encoder, l):\n",
    "    return encoder[l]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    train_data = create_utterances('Friends/friends_train.json', 'train')\n",
    "    valid_data = create_utterances('Friends/friends_dev.json', 'valid')\n",
    "    test_data = create_utterances('Friends/friends_test.json', 'test')\n",
    "    \n",
    "    ## encode the emotion and dialog act labels ##\n",
    "    all_emotion_labels =  set(train_data['emotion_label'])\n",
    "    emotion_label_encoder, emotion_label_decoder = {}, {}\n",
    "\n",
    "\n",
    "    for i, label in enumerate(all_emotion_labels):\n",
    "        emotion_label_encoder[label] = i\n",
    "        emotion_label_decoder[i] = label\n",
    "\n",
    "\n",
    "    pickle.dump(emotion_label_encoder, open('emotion_label_encoder.pkl', 'wb'))\n",
    "    pickle.dump(emotion_label_decoder, open('emotion_label_decoder.pkl', 'wb'))\n",
    "\n",
    "    train_data['encoded_emotion_label'] = train_data['emotion_label'].map(lambda x: encode_labels(emotion_label_encoder, x))\n",
    "    test_data['encoded_emotion_label'] = test_data['emotion_label'].map(lambda x: encode_labels(emotion_label_encoder, x))\n",
    "    valid_data['encoded_emotion_label'] = valid_data['emotion_label'].map(lambda x: encode_labels(emotion_label_encoder, x))\n",
    "    \n",
    "    \n",
    "    ## tokenize all sentences ##\n",
    "    all_text = list(train_data['sentence'])\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(all_text)\n",
    "    pickle.dump(tokenizer, open('tokenizer.pkl', 'wb'))\n",
    "\n",
    "    ## convert the sentences into sequences ##\n",
    "    train_sequence = tokenizer.texts_to_sequences(list(train_data['sentence']))\n",
    "    valid_sequence = tokenizer.texts_to_sequences(list(valid_data['sentence']))\n",
    "    test_sequence = tokenizer.texts_to_sequences(list(test_data['sentence']))\n",
    "    \n",
    "    train_data['sentence_length'] = [len(item) for item in train_sequence]\n",
    "    valid_data['sentence_length'] = [len(item) for item in valid_sequence]\n",
    "    test_data['sentence_length'] = [len(item) for item in test_sequence]\n",
    "    \n",
    "    max_num_tokens = 250\n",
    "\n",
    "    train_sequence = pad_sequences(train_sequence, maxlen=max_num_tokens, padding='post')\n",
    "    valid_sequence = pad_sequences(valid_sequence, maxlen=max_num_tokens, padding='post')\n",
    "    test_sequence = pad_sequences(test_sequence, maxlen=max_num_tokens, padding='post')\n",
    "\n",
    "    train_data['sequence'] = list(train_sequence)\n",
    "    valid_data['sequence'] = list(valid_sequence)\n",
    "    test_data['sequence'] = list(test_sequence)\n",
    "    \n",
    "   \n",
    "    \n",
    "    ## save pretrained embedding matrix ##\n",
    "    glv_vector = load_pretrained_glove()\n",
    "    word_vector_length = len(glv_vector['the'])\n",
    "    word_index = tokenizer.word_index\n",
    "    inv_word_index = {v: k for k, v in word_index.items()}\n",
    "    num_unique_words = len(word_index)\n",
    "    glv_embedding_matrix = np.zeros((num_unique_words+1, word_vector_length))\n",
    "\n",
    "    for j in range(1, num_unique_words+1):\n",
    "        try:\n",
    "            glv_embedding_matrix[j] = glv_vector[inv_word_index[j]]\n",
    "        except KeyError:\n",
    "            glv_embedding_matrix[j] = np.random.randn(word_vector_length)/200\n",
    "\n",
    "    np.ndarray.dump(glv_embedding_matrix, open('glv_embedding_matrix', 'wb'))\n",
    "    print ('Done. Completed preprocessing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814ac1e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data['emotion_true'] = pd.get_dummies(train_data['encoded_emotion_label']).values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4ee2ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>speaker</th>\n",
       "      <th>conv_id</th>\n",
       "      <th>encoded_emotion_label</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>sequence</th>\n",
       "      <th>emotion_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also i was the point person on my company's tr...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>tr_c0</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>[371, 1, 31, 5, 695, 401, 33, 26, 2758, 2759, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you must have had your hands full</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>tr_c0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>[2, 311, 17, 98, 44, 643, 760, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that i did that i did</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>tr_c0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>[9, 1, 48, 9, 1, 48, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>so let us talk a little bit about your duties</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>tr_c0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>[23, 84, 79, 175, 7, 100, 402, 54, 44, 1470, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my duties all right</td>\n",
       "      <td>surprise</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>tr_c0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[26, 1470, 34, 36, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10556</th>\n",
       "      <td>you or me</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>tr_c719</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>[2, 112, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10557</th>\n",
       "      <td>i got it uh joey women do not have adam's apples</td>\n",
       "      <td>non-neutral</td>\n",
       "      <td>Ross</td>\n",
       "      <td>tr_c719</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>[1, 57, 6, 51, 81, 316, 12, 8, 17, 2757, 5888,...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10558</th>\n",
       "      <td>you guys are messing with me right</td>\n",
       "      <td>surprise</td>\n",
       "      <td>Joey</td>\n",
       "      <td>tr_c719</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>[2, 87, 13, 2747, 37, 20, 36, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10559</th>\n",
       "      <td>yeah</td>\n",
       "      <td>neutral</td>\n",
       "      <td>All</td>\n",
       "      <td>tr_c719</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[24, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10560</th>\n",
       "      <td>that was a good one for a second there i was l...</td>\n",
       "      <td>non-neutral</td>\n",
       "      <td>Joey</td>\n",
       "      <td>tr_c719</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>[9, 31, 7, 77, 66, 35, 7, 234, 46, 1, 31, 45, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10561 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence emotion_label  \\\n",
       "0      also i was the point person on my company's tr...       neutral   \n",
       "1                      you must have had your hands full       neutral   \n",
       "2                                  that i did that i did       neutral   \n",
       "3          so let us talk a little bit about your duties       neutral   \n",
       "4                                    my duties all right      surprise   \n",
       "...                                                  ...           ...   \n",
       "10556                                          you or me       neutral   \n",
       "10557   i got it uh joey women do not have adam's apples   non-neutral   \n",
       "10558                 you guys are messing with me right      surprise   \n",
       "10559                                               yeah       neutral   \n",
       "10560  that was a good one for a second there i was l...   non-neutral   \n",
       "\n",
       "               speaker  conv_id  encoded_emotion_label  sentence_length  \\\n",
       "0             Chandler    tr_c0                      7               18   \n",
       "1      The Interviewer    tr_c0                      7                7   \n",
       "2             Chandler    tr_c0                      7                6   \n",
       "3      The Interviewer    tr_c0                      7               10   \n",
       "4             Chandler    tr_c0                      4                4   \n",
       "...                ...      ...                    ...              ...   \n",
       "10556         Chandler  tr_c719                      7                3   \n",
       "10557             Ross  tr_c719                      3               11   \n",
       "10558             Joey  tr_c719                      4                7   \n",
       "10559              All  tr_c719                      7                1   \n",
       "10560             Joey  tr_c719                      3               13   \n",
       "\n",
       "                                                sequence  \\\n",
       "0      [371, 1, 31, 5, 695, 401, 33, 26, 2758, 2759, ...   \n",
       "1      [2, 311, 17, 98, 44, 643, 760, 0, 0, 0, 0, 0, ...   \n",
       "2      [9, 1, 48, 9, 1, 48, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "3      [23, 84, 79, 175, 7, 100, 402, 54, 44, 1470, 0...   \n",
       "4      [26, 1470, 34, 36, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                  ...   \n",
       "10556  [2, 112, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10557  [1, 57, 6, 51, 81, 316, 12, 8, 17, 2757, 5888,...   \n",
       "10558  [2, 87, 13, 2747, 37, 20, 36, 0, 0, 0, 0, 0, 0...   \n",
       "10559  [24, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "10560  [9, 31, 7, 77, 66, 35, 7, 234, 46, 1, 31, 45, ...   \n",
       "\n",
       "                   emotion_true  \n",
       "0      [0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "4      [0, 0, 0, 0, 1, 0, 0, 0]  \n",
       "...                         ...  \n",
       "10556  [0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "10557  [0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "10558  [0, 0, 0, 0, 1, 0, 0, 0]  \n",
       "10559  [0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "10560  [0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "\n",
       "[10561 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "f9c2ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['sequence'] = np.array(train_data['sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "19f935c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_train_data = train_data.groupby(\"conv_id\").agg(list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "86f8bcb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>speaker</th>\n",
       "      <th>encoded_emotion_label</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>sequence</th>\n",
       "      <th>emotion_true</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tr_c0</th>\n",
       "      <td>[also i was the point person on my company's t...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
       "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
       "      <td>[7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 5, 7, 4, 7, 4, ...</td>\n",
       "      <td>[18, 7, 6, 10, 4, 16, 2, 18, 3, 5, 7, 28, 1, 7...</td>\n",
       "      <td>[[371, 1, 31, 5, 695, 401, 33, 26, 2758, 2759,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr_c1</th>\n",
       "      <td>[hey mon, hey hey hey you want to hear somethi...</td>\n",
       "      <td>[neutral, neutral, joy, sadness, surprise, neu...</td>\n",
       "      <td>[Chandler, Monica, Chandler, Monica, Chandler,...</td>\n",
       "      <td>[7, 7, 6, 2, 4, 7, 3, 2, 7, 7, 6, 7, 3, 4, 4, ...</td>\n",
       "      <td>[2, 10, 3, 8, 2, 12, 10, 2, 5, 6, 2, 5, 4, 8, ...</td>\n",
       "      <td>[[28, 509, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr_c10</th>\n",
       "      <td>[go go go, oh yeah now everybody wants to be u...</td>\n",
       "      <td>[joy, joy, non-neutral, surprise, neutral, neu...</td>\n",
       "      <td>[Ross, Rachel, Phoebe, Monica, Phoebe, Ross]</td>\n",
       "      <td>[6, 6, 3, 4, 7, 7]</td>\n",
       "      <td>[3, 10, 1, 6, 9, 10]</td>\n",
       "      <td>[[43, 43, 43, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr_c100</th>\n",
       "      <td>[ooh oh no i have to go i have a massage appoi...</td>\n",
       "      <td>[non-neutral, neutral, neutral, joy, non-neutr...</td>\n",
       "      <td>[Phoebe, Eric, Phoebe, Eric, Mona, Ross, Dr. G...</td>\n",
       "      <td>[3, 7, 7, 6, 3, 7, 0, 2]</td>\n",
       "      <td>[12, 13, 13, 7, 10, 6, 19, 10]</td>\n",
       "      <td>[[219, 11, 16, 1, 17, 4, 43, 1, 17, 7, 1328, 1...</td>\n",
       "      <td>[[0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr_c101</th>\n",
       "      <td>[okay so we will just stay married, yes exactl...</td>\n",
       "      <td>[joy, joy, joy, non-neutral, fear, non-neutral...</td>\n",
       "      <td>[Rachel, Ross, Rachel, Ross, Rachel, Ross, Rac...</td>\n",
       "      <td>[6, 6, 6, 3, 5, 3, 4, 7, 3, 6, 7, 2, 7, 7, 3, ...</td>\n",
       "      <td>[7, 2, 9, 19, 15, 12, 10, 9, 1, 27, 2, 5, 3, 2...</td>\n",
       "      <td>[[22, 23, 18, 41, 25, 254, 186, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr_c95</th>\n",
       "      <td>[hey joey you wanted to talk to me, i do not k...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
       "      <td>[Tag, Joey, Tag, Joey, Tag, Joey]</td>\n",
       "      <td>[7, 7, 7, 7, 4, 6]</td>\n",
       "      <td>[8, 11, 6, 13, 1, 3]</td>\n",
       "      <td>[[28, 81, 2, 198, 4, 175, 4, 20, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr_c96</th>\n",
       "      <td>[oh danielle i was not expecting the machine g...</td>\n",
       "      <td>[surprise, neutral, non-neutral, non-neutral, ...</td>\n",
       "      <td>[Chandler, Monica, Chandler, Ross, Chandler, C...</td>\n",
       "      <td>[4, 7, 3, 3, 5, 5, 3, 4, 0, 1, 1, 1, 3, 0, 3, ...</td>\n",
       "      <td>[21, 2, 5, 5, 2, 12, 21, 12, 9, 6, 9, 9, 4, 7,...</td>\n",
       "      <td>[[11, 3176, 1, 31, 8, 1150, 5, 503, 136, 20, 7...</td>\n",
       "      <td>[[0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr_c97</th>\n",
       "      <td>[y'know they say a watched pot never beeps, it...</td>\n",
       "      <td>[neutral, non-neutral, neutral, anger, neutral...</td>\n",
       "      <td>[Monica, Phoebe, Monica, Phoebe, Monica, Phoeb...</td>\n",
       "      <td>[7, 3, 7, 0, 7, 7, 7, 7, 7, 2, 2, 2, 2]</td>\n",
       "      <td>[8, 20, 12, 7, 6, 1, 6, 5, 2, 2, 2, 19, 26]</td>\n",
       "      <td>[[53, 63, 101, 7, 3180, 3181, 128, 2103, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr_c98</th>\n",
       "      <td>[ok bye well monica's not coming it is just go...</td>\n",
       "      <td>[neutral, neutral, neutral, joy, non-neutral, ...</td>\n",
       "      <td>[Ross, Chandler, Ross, Chandler, Ross, Chandle...</td>\n",
       "      <td>[7, 7, 7, 6, 3, 3, 4, 1, 4, 7, 3, 3, 7]</td>\n",
       "      <td>[15, 14, 8, 21, 2, 2, 15, 9, 18, 1, 6, 8, 3]</td>\n",
       "      <td>[[113, 179, 30, 488, 8, 251, 6, 3, 25, 29, 4, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr_c99</th>\n",
       "      <td>[ok so it is just because it was my table i ha...</td>\n",
       "      <td>[non-neutral, neutral, anger, non-neutral, non...</td>\n",
       "      <td>[Chandler, Joey, Chandler, Joey, Chandler, Joe...</td>\n",
       "      <td>[3, 7, 0, 3, 3, 4, 1, 7, 3, 7, 3, 7, 7, 3, 7, ...</td>\n",
       "      <td>[17, 4, 13, 6, 17, 4, 17, 8, 8, 1, 9, 2, 18, 5...</td>\n",
       "      <td>[[113, 23, 6, 3, 25, 89, 6, 31, 26, 512, 1, 17...</td>\n",
       "      <td>[[0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  sentence  \\\n",
       "conv_id                                                      \n",
       "tr_c0    [also i was the point person on my company's t...   \n",
       "tr_c1    [hey mon, hey hey hey you want to hear somethi...   \n",
       "tr_c10   [go go go, oh yeah now everybody wants to be u...   \n",
       "tr_c100  [ooh oh no i have to go i have a massage appoi...   \n",
       "tr_c101  [okay so we will just stay married, yes exactl...   \n",
       "...                                                    ...   \n",
       "tr_c95   [hey joey you wanted to talk to me, i do not k...   \n",
       "tr_c96   [oh danielle i was not expecting the machine g...   \n",
       "tr_c97   [y'know they say a watched pot never beeps, it...   \n",
       "tr_c98   [ok bye well monica's not coming it is just go...   \n",
       "tr_c99   [ok so it is just because it was my table i ha...   \n",
       "\n",
       "                                             emotion_label  \\\n",
       "conv_id                                                      \n",
       "tr_c0    [neutral, neutral, neutral, neutral, surprise,...   \n",
       "tr_c1    [neutral, neutral, joy, sadness, surprise, neu...   \n",
       "tr_c10   [joy, joy, non-neutral, surprise, neutral, neu...   \n",
       "tr_c100  [non-neutral, neutral, neutral, joy, non-neutr...   \n",
       "tr_c101  [joy, joy, joy, non-neutral, fear, non-neutral...   \n",
       "...                                                    ...   \n",
       "tr_c95   [neutral, neutral, neutral, neutral, surprise,...   \n",
       "tr_c96   [surprise, neutral, non-neutral, non-neutral, ...   \n",
       "tr_c97   [neutral, non-neutral, neutral, anger, neutral...   \n",
       "tr_c98   [neutral, neutral, neutral, joy, non-neutral, ...   \n",
       "tr_c99   [non-neutral, neutral, anger, non-neutral, non...   \n",
       "\n",
       "                                                   speaker  \\\n",
       "conv_id                                                      \n",
       "tr_c0    [Chandler, The Interviewer, Chandler, The Inte...   \n",
       "tr_c1    [Chandler, Monica, Chandler, Monica, Chandler,...   \n",
       "tr_c10        [Ross, Rachel, Phoebe, Monica, Phoebe, Ross]   \n",
       "tr_c100  [Phoebe, Eric, Phoebe, Eric, Mona, Ross, Dr. G...   \n",
       "tr_c101  [Rachel, Ross, Rachel, Ross, Rachel, Ross, Rac...   \n",
       "...                                                    ...   \n",
       "tr_c95                   [Tag, Joey, Tag, Joey, Tag, Joey]   \n",
       "tr_c96   [Chandler, Monica, Chandler, Ross, Chandler, C...   \n",
       "tr_c97   [Monica, Phoebe, Monica, Phoebe, Monica, Phoeb...   \n",
       "tr_c98   [Ross, Chandler, Ross, Chandler, Ross, Chandle...   \n",
       "tr_c99   [Chandler, Joey, Chandler, Joey, Chandler, Joe...   \n",
       "\n",
       "                                     encoded_emotion_label  \\\n",
       "conv_id                                                      \n",
       "tr_c0    [7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 5, 7, 4, 7, 4, ...   \n",
       "tr_c1    [7, 7, 6, 2, 4, 7, 3, 2, 7, 7, 6, 7, 3, 4, 4, ...   \n",
       "tr_c10                                  [6, 6, 3, 4, 7, 7]   \n",
       "tr_c100                           [3, 7, 7, 6, 3, 7, 0, 2]   \n",
       "tr_c101  [6, 6, 6, 3, 5, 3, 4, 7, 3, 6, 7, 2, 7, 7, 3, ...   \n",
       "...                                                    ...   \n",
       "tr_c95                                  [7, 7, 7, 7, 4, 6]   \n",
       "tr_c96   [4, 7, 3, 3, 5, 5, 3, 4, 0, 1, 1, 1, 3, 0, 3, ...   \n",
       "tr_c97             [7, 3, 7, 0, 7, 7, 7, 7, 7, 2, 2, 2, 2]   \n",
       "tr_c98             [7, 7, 7, 6, 3, 3, 4, 1, 4, 7, 3, 3, 7]   \n",
       "tr_c99   [3, 7, 0, 3, 3, 4, 1, 7, 3, 7, 3, 7, 7, 3, 7, ...   \n",
       "\n",
       "                                           sentence_length  \\\n",
       "conv_id                                                      \n",
       "tr_c0    [18, 7, 6, 10, 4, 16, 2, 18, 3, 5, 7, 28, 1, 7...   \n",
       "tr_c1    [2, 10, 3, 8, 2, 12, 10, 2, 5, 6, 2, 5, 4, 8, ...   \n",
       "tr_c10                                [3, 10, 1, 6, 9, 10]   \n",
       "tr_c100                     [12, 13, 13, 7, 10, 6, 19, 10]   \n",
       "tr_c101  [7, 2, 9, 19, 15, 12, 10, 9, 1, 27, 2, 5, 3, 2...   \n",
       "...                                                    ...   \n",
       "tr_c95                                [8, 11, 6, 13, 1, 3]   \n",
       "tr_c96   [21, 2, 5, 5, 2, 12, 21, 12, 9, 6, 9, 9, 4, 7,...   \n",
       "tr_c97         [8, 20, 12, 7, 6, 1, 6, 5, 2, 2, 2, 19, 26]   \n",
       "tr_c98        [15, 14, 8, 21, 2, 2, 15, 9, 18, 1, 6, 8, 3]   \n",
       "tr_c99   [17, 4, 13, 6, 17, 4, 17, 8, 8, 1, 9, 2, 18, 5...   \n",
       "\n",
       "                                                  sequence  \\\n",
       "conv_id                                                      \n",
       "tr_c0    [[371, 1, 31, 5, 695, 401, 33, 26, 2758, 2759,...   \n",
       "tr_c1    [[28, 509, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "tr_c10   [[43, 43, 43, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "tr_c100  [[219, 11, 16, 1, 17, 4, 43, 1, 17, 7, 1328, 1...   \n",
       "tr_c101  [[22, 23, 18, 41, 25, 254, 186, 0, 0, 0, 0, 0,...   \n",
       "...                                                    ...   \n",
       "tr_c95   [[28, 81, 2, 198, 4, 175, 4, 20, 0, 0, 0, 0, 0...   \n",
       "tr_c96   [[11, 3176, 1, 31, 8, 1150, 5, 503, 136, 20, 7...   \n",
       "tr_c97   [[53, 63, 101, 7, 3180, 3181, 128, 2103, 0, 0,...   \n",
       "tr_c98   [[113, 179, 30, 488, 8, 251, 6, 3, 25, 29, 4, ...   \n",
       "tr_c99   [[113, 23, 6, 3, 25, 89, 6, 31, 26, 512, 1, 17...   \n",
       "\n",
       "                                              emotion_true  \n",
       "conv_id                                                     \n",
       "tr_c0    [[0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, ...  \n",
       "tr_c1    [[0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, ...  \n",
       "tr_c10   [[0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, ...  \n",
       "tr_c100  [[0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, ...  \n",
       "tr_c101  [[0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                    ...  \n",
       "tr_c95   [[0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, ...  \n",
       "tr_c96   [[0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, ...  \n",
       "tr_c97   [[0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, ...  \n",
       "tr_c98   [[0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, ...  \n",
       "tr_c99   [[0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[720 rows x 7 columns]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "4cfdb411",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLabelBinarizer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.lb = LabelBinarizer()\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Convert X to array\n",
    "        X = np.array(X)\n",
    "        # Fit X using the LabelBinarizer object\n",
    "        self.lb.fit(X)\n",
    "        # Save the classes\n",
    "        self.classes_ = self.lb.classes_\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        # Convert X to array\n",
    "        X = np.array(X)\n",
    "        # Fit + transform X using the LabelBinarizer object\n",
    "        Xlb = self.lb.fit_transform(X)\n",
    "        # Save the classes\n",
    "        self.classes_ = self.lb.classes_\n",
    "        if len(self.classes_) == 2:\n",
    "            Xlb = np.hstack((Xlb, 1 - Xlb))\n",
    "        return Xlb\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Convert X to array\n",
    "        X = np.array(X)\n",
    "        # Transform X using the LabelBinarizer object\n",
    "        Xlb = self.lb.transform(X)\n",
    "        if len(self.classes_) == 2:\n",
    "            Xlb = np.hstack((Xlb, 1 - Xlb))\n",
    "        return Xlb\n",
    "\n",
    "    def inverse_transform(self, Xlb):\n",
    "        # Convert Xlb to array\n",
    "        Xlb = np.array(Xlb)\n",
    "        if len(self.classes_) == 2:\n",
    "            X = self.lb.inverse_transform(Xlb[:, 0])\n",
    "        else:\n",
    "            X = self.lb.inverse_transform(Xlb)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "bb3798b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_train_data['encoded_speaker'] = dialogue_train_data['speaker'].apply(lambda s: MyLabelBinarizer().fit_transform(s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "ea6bee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_train_data['sequence'] = dialogue_train_data['sequence'].apply(lambda s: np.array(np.array(s)))\n",
    "dialogue_train_data['encoded_emotion_label'] = dialogue_train_data['encoded_emotion_label'].apply(lambda s: np.array(np.array(s)))\n",
    "dialogue_train_data['encoded_speaker'] = dialogue_train_data['encoded_speaker'].apply(lambda s: np.array(np.array(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "217f946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_train_data['max_sentence_length'] = dialogue_train_data['sentence_length'].apply(lambda s: max(s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "7112d739",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dialogue_train_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "2279554b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>speaker</th>\n",
       "      <th>encoded_emotion_label</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>sequence</th>\n",
       "      <th>emotion_true</th>\n",
       "      <th>encoded_speaker</th>\n",
       "      <th>max_sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr_c0</td>\n",
       "      <td>[also i was the point person on my company's t...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
       "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
       "      <td>[7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 5, 7, 4, 7, 4, ...</td>\n",
       "      <td>[18, 7, 6, 10, 4, 16, 2, 18, 3, 5, 7, 28, 1, 7...</td>\n",
       "      <td>[[371, 1, 31, 5, 695, 401, 33, 26, 2758, 2759,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[1, 0, 0, 0], [0, 0, 0, 1], [1, 0, 0, 0], [0,...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr_c1</td>\n",
       "      <td>[hey mon, hey hey hey you want to hear somethi...</td>\n",
       "      <td>[neutral, neutral, joy, sadness, surprise, neu...</td>\n",
       "      <td>[Chandler, Monica, Chandler, Monica, Chandler,...</td>\n",
       "      <td>[7, 7, 6, 2, 4, 7, 3, 2, 7, 7, 6, 7, 3, 4, 4, ...</td>\n",
       "      <td>[2, 10, 3, 8, 2, 12, 10, 2, 5, 6, 2, 5, 4, 8, ...</td>\n",
       "      <td>[[28, 509, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[1, 0, 0, 0], [0, 0, 1, 0], [1, 0, 0, 0], [0,...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tr_c10</td>\n",
       "      <td>[go go go, oh yeah now everybody wants to be u...</td>\n",
       "      <td>[joy, joy, non-neutral, surprise, neutral, neu...</td>\n",
       "      <td>[Ross, Rachel, Phoebe, Monica, Phoebe, Ross]</td>\n",
       "      <td>[6, 6, 3, 4, 7, 7]</td>\n",
       "      <td>[3, 10, 1, 6, 9, 10]</td>\n",
       "      <td>[[43, 43, 43, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 1, 0], [0, 1, 0, 0], [1,...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tr_c100</td>\n",
       "      <td>[ooh oh no i have to go i have a massage appoi...</td>\n",
       "      <td>[non-neutral, neutral, neutral, joy, non-neutr...</td>\n",
       "      <td>[Phoebe, Eric, Phoebe, Eric, Mona, Ross, Dr. G...</td>\n",
       "      <td>[3, 7, 7, 6, 3, 7, 0, 2]</td>\n",
       "      <td>[12, 13, 13, 7, 10, 6, 19, 10]</td>\n",
       "      <td>[[219, 11, 16, 1, 17, 4, 43, 1, 17, 7, 1328, 1...</td>\n",
       "      <td>[[0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 1, 0], [0, 1, 0, 0, 0], [0, 0, 0, 1...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tr_c101</td>\n",
       "      <td>[okay so we will just stay married, yes exactl...</td>\n",
       "      <td>[joy, joy, joy, non-neutral, fear, non-neutral...</td>\n",
       "      <td>[Rachel, Ross, Rachel, Ross, Rachel, Ross, Rac...</td>\n",
       "      <td>[6, 6, 6, 3, 5, 3, 4, 7, 3, 6, 7, 2, 7, 7, 3, ...</td>\n",
       "      <td>[7, 2, 9, 19, 15, 12, 10, 9, 1, 27, 2, 5, 3, 2...</td>\n",
       "      <td>[[22, 23, 18, 41, 25, 254, 186, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 1], [1, 0], [0, 1], [1, 0], [0, 1], [1, 0...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conv_id                                           sentence  \\\n",
       "0    tr_c0  [also i was the point person on my company's t...   \n",
       "1    tr_c1  [hey mon, hey hey hey you want to hear somethi...   \n",
       "2   tr_c10  [go go go, oh yeah now everybody wants to be u...   \n",
       "3  tr_c100  [ooh oh no i have to go i have a massage appoi...   \n",
       "4  tr_c101  [okay so we will just stay married, yes exactl...   \n",
       "\n",
       "                                       emotion_label  \\\n",
       "0  [neutral, neutral, neutral, neutral, surprise,...   \n",
       "1  [neutral, neutral, joy, sadness, surprise, neu...   \n",
       "2  [joy, joy, non-neutral, surprise, neutral, neu...   \n",
       "3  [non-neutral, neutral, neutral, joy, non-neutr...   \n",
       "4  [joy, joy, joy, non-neutral, fear, non-neutral...   \n",
       "\n",
       "                                             speaker  \\\n",
       "0  [Chandler, The Interviewer, Chandler, The Inte...   \n",
       "1  [Chandler, Monica, Chandler, Monica, Chandler,...   \n",
       "2       [Ross, Rachel, Phoebe, Monica, Phoebe, Ross]   \n",
       "3  [Phoebe, Eric, Phoebe, Eric, Mona, Ross, Dr. G...   \n",
       "4  [Rachel, Ross, Rachel, Ross, Rachel, Ross, Rac...   \n",
       "\n",
       "                               encoded_emotion_label  \\\n",
       "0  [7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 5, 7, 4, 7, 4, ...   \n",
       "1  [7, 7, 6, 2, 4, 7, 3, 2, 7, 7, 6, 7, 3, 4, 4, ...   \n",
       "2                                 [6, 6, 3, 4, 7, 7]   \n",
       "3                           [3, 7, 7, 6, 3, 7, 0, 2]   \n",
       "4  [6, 6, 6, 3, 5, 3, 4, 7, 3, 6, 7, 2, 7, 7, 3, ...   \n",
       "\n",
       "                                     sentence_length  \\\n",
       "0  [18, 7, 6, 10, 4, 16, 2, 18, 3, 5, 7, 28, 1, 7...   \n",
       "1  [2, 10, 3, 8, 2, 12, 10, 2, 5, 6, 2, 5, 4, 8, ...   \n",
       "2                               [3, 10, 1, 6, 9, 10]   \n",
       "3                     [12, 13, 13, 7, 10, 6, 19, 10]   \n",
       "4  [7, 2, 9, 19, 15, 12, 10, 9, 1, 27, 2, 5, 3, 2...   \n",
       "\n",
       "                                            sequence  \\\n",
       "0  [[371, 1, 31, 5, 695, 401, 33, 26, 2758, 2759,...   \n",
       "1  [[28, 509, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2  [[43, 43, 43, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3  [[219, 11, 16, 1, 17, 4, 43, 1, 17, 7, 1328, 1...   \n",
       "4  [[22, 23, 18, 41, 25, 254, 186, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                        emotion_true  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, ...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, ...   \n",
       "2  [[0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, ...   \n",
       "3  [[0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, ...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                     encoded_speaker  max_sentence_length  \n",
       "0  [[1, 0, 0, 0], [0, 0, 0, 1], [1, 0, 0, 0], [0,...                   28  \n",
       "1  [[1, 0, 0, 0], [0, 0, 1, 0], [1, 0, 0, 0], [0,...                   12  \n",
       "2  [[0, 0, 0, 1], [0, 0, 1, 0], [0, 1, 0, 0], [1,...                   10  \n",
       "3  [[0, 0, 0, 1, 0], [0, 1, 0, 0, 0], [0, 0, 0, 1...                   19  \n",
       "4  [[0, 1], [1, 0], [0, 1], [1, 0], [0, 1], [1, 0...                   27  "
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "3c0077f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 10)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "f25944c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNExtractor(k.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_size, max_num_tokens,glv_embedding_matrix, filters, kernel_sizes, dropout):\n",
    "        super(CNNExtractor, self).__init__()\n",
    "                \n",
    "        self.embedding = k.layers.Embedding(input_dim=vocab_size, output_dim= embedding_dim, \n",
    "                                            input_length=max_num_tokens, weights = [glv_embedding_matrix])\n",
    "        self.convs1 = k.layers.Conv1D(filters, \n",
    "                                           kernel_sizes[0], \n",
    "                                           activation='relu')\n",
    "        self.convs2 = k.layers.Conv1D(filters, \n",
    "                                           kernel_sizes[1], \n",
    "                                           activation='relu')\n",
    "        self.convs3 = k.layers.Conv1D(filters, \n",
    "                                           kernel_sizes[2], \n",
    "                                           activation='relu')\n",
    "        \n",
    "        self.pooling = k.layers.GlobalMaxPooling1D()\n",
    "        self.concatanate = k.layers.Concatenate()\n",
    "        self.dropout = k.layers.Dropout(dropout)\n",
    "        self.dense = k.layers.Dense(output_size, input_shape=(len(kernel_sizes) * filters,), activation='relu')\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def call(self, inputs):\n",
    "         # input size = (num_words = 250)\n",
    "         #in the original code the input is equals to (num_utt, batch, num_words)\n",
    "        print(inputs.shape)\n",
    "        num_utt, batch, num_words = inputs.shape\n",
    "        x = tf.reshape(inputs, [batch*num_utt, num_words])\n",
    "\n",
    "        x = self.embedding(x) # x size = (batch*num_utt, num_words = 250, embedding = 300)\n",
    "        #x = tf.expand_dims(x, axis=-1) # x size =  (num_words = 250, embedding = 300, num_utt * batch = 1)\n",
    "        x = tf.transpose(x, [0, 2, 1]) # x size =  (num_utt * batch = 1, embedding = 300,num_words = 250 )\n",
    "        \n",
    "\n",
    "    \n",
    "        conv1_x = self.pooling(self.convs1(x)) # conv1_x size =  (num_utt * batch = 1, 50 )\n",
    "        conv2_x = self.pooling(self.convs2(x)) # conv2_x size =  (num_utt * batch = 1, 50 )\n",
    "        conv3_x = self.pooling(self.convs3(x)) # conv3_x size =  (num_utt * batch = 1, 50 )\n",
    "        x = self.concatanate([conv1_x, conv2_x, conv3_x]) # x size =  (num_utt * batch = 1, 150 )\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x) \n",
    "        print(\"END TR SHAPE\")\n",
    "        print(x.shape)\n",
    "        x = tf.reshape(x, [num_utt, batch, self.output_size])\n",
    "        # x size =  (num_utt * batch = 1, output_size = 100 )\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "cf280853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720,)"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_train_data['sequence'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53260bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "9cdc8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalGRU(k.layers.Layer):\n",
    "    def __init__(self, D_g):\n",
    "        \n",
    "        super(GlobalGRU, self).__init__()\n",
    "        self.global_gru = k.layers.GRU(D_g,\n",
    "                                bias_initializer=\"ones\",\n",
    "                                dropout=0.1,\n",
    "                                recurrent_initializer='glorot_uniform')\n",
    "        self.dropout = k.layers.Dropout(0.5)\n",
    "\n",
    "# h_P_previous -> previous party state\n",
    "#t_r _> textual representation\n",
    "#h_G_previous _> previous global state\n",
    "    def call(self, t_r, h_P_previous, h_G_previous):\n",
    "\n",
    "        t_r_h_P = tf.concat([h_P_previous, t_r], axis=-1)\n",
    "    \n",
    "        t_r_h_P = tf.expand_dims(t_r_h_P, axis=-1)\n",
    "\n",
    "        output = self.global_gru(t_r_h_P, initial_state=h_G_previous)\n",
    "\n",
    "        return self.dropout(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "c84f600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartyGRU(k.layers.Layer):\n",
    "    def __init__(self, D_p):\n",
    "        super(PartyGRU, self).__init__()\n",
    "        \n",
    "        self.party_gru = k.layers.GRU(D_p,\n",
    "                                bias_initializer=\"ones\",\n",
    "                                dropout=0.1,\n",
    "                                recurrent_initializer='glorot_uniform')\n",
    "        self.dropout = k.layers.Dropout(0.5)\n",
    "\n",
    "#c_t -> current context \n",
    "#t_r -> textual representation\n",
    "#h_P_previous -> previous party state\n",
    "    def call(self, c_t, t_r, h_P_previous):\n",
    "\n",
    "        t_r_c_t = tf.concat([c_t, t_r], axis=-1)\n",
    "        t_r_c_t = tf.expand_dims(t_r_c_t, axis=-1)\n",
    "\n",
    "        return self.dropout(self.party_gru(t_r_c_t, initial_state=h_P_previous))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "d5d73096",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionGRU(k.layers.Layer):\n",
    "    def __init__(self, D_e):\n",
    "        super(EmotionGRU, self).__init__()\n",
    "\n",
    "        self.emotion_gru = k.layers.GRU(D_e,\n",
    "                                bias_initializer=\"ones\",\n",
    "                                dropout=0.1,\n",
    "                                recurrent_initializer='glorot_uniform')\n",
    "        self.dropout = k.layers.Dropout(0.5)\n",
    "\n",
    "#h_E_previous -> previous emotion state\n",
    "#h_P -> current party state\n",
    "    def call(self, h_P, h_E_previous):\n",
    "        \n",
    "        h_P = tf.expand_dims(h_P, axis=-1)\n",
    "        return self.dropout(self.emotion_gru(h_P, initial_state=h_E_previous))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "1d9f9446",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassificationDense(k.layers.Layer):\n",
    "    def __init__(self, D_c, n_classes):\n",
    "        super(EmotionClassificationDense, self).__init__()\n",
    "\n",
    "        self.classification = k.layers.Dense(2*D_c, activation=\"relu\")\n",
    "\n",
    "        self.y = k.layers.Dense(n_classes, activation=\"softmax\", kernel_regularizer='l2')\n",
    "\n",
    "        \n",
    "    def call(self, h_E):\n",
    "        output = self.classification(h_E)\n",
    "        return self.y(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "36ddd8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(k.layers.Layer):\n",
    "    def __init__(self, D_g):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.dense = k.layers.Dense(D_g)\n",
    "\n",
    "\n",
    "    def call(self, h_G_all, t_r):\n",
    "        \n",
    "\n",
    "        H_g = np.array(h_G_all) #Hg = (32, 150, n_iterations)\n",
    "        H_g = tf.transpose(H_g, [1, 2, 0]) \n",
    "        \n",
    "        t_r =  self.dense(t_r)  #  (32, 1, 150)\n",
    "        t_r = tf.expand_dims(t_r, 1) \n",
    "\n",
    "        score = tf.matmul(t_r, H_g, transpose_b=False)\n",
    "        a_t = tf.nn.softmax(score, axis = 0) # 32, 1, 2\n",
    "     \n",
    "        aux = tf.transpose(H_g, [0,2,1]) # 1 , 2, 150\n",
    "        c_t = tf.matmul(a_t, aux) #150, 1, 32\n",
    "        \n",
    "        return c_t[:,0,:] #32, 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "027e00b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueRNN(k.Model):\n",
    "    def __init__(self, D_g, D_p, D_e, D_c, n_classes, vocab_size, embedding_dim, cnn_output_size ,\n",
    "                 max_num_tokens, glv_embedding_matrix, filters, kernel_sizes, dropout, batch_size):\n",
    "        \n",
    "        super(DialogueRNN, self).__init__()\n",
    "        \n",
    "        self.D_g = D_g\n",
    "        self.D_p = D_p\n",
    "        self.D_e = D_e\n",
    "        self.D_c = D_c\n",
    "        \n",
    "        self.cnnTextualRepresentation = CNNExtractor(vocab_size, embedding_dim, cnn_output_size, \n",
    "                                            max_num_tokens,glv_embedding_matrix, filters, kernel_sizes, dropout)\n",
    "        \n",
    "        self.attention = AttentionBlock(D_g)\n",
    "        self.partyGRU = PartyGRU(D_p)\n",
    "        self.globalGRU = GlobalGRU(D_g)\n",
    "        self.emotionGRU = EmotionGRU(D_e)\n",
    "        \n",
    "        self.classificationDense = EmotionClassificationDense(D_c, n_classes)\n",
    "        self.batch_size = batch_size\n",
    "    #for each conversation \n",
    "    def call(self, messages, speakers):  \n",
    "        \n",
    "        number_of_speakers =  speakers.shape[2]\n",
    "        print(\"number_of_speakers\")\n",
    "        print(number_of_speakers)\n",
    "        speakers_states = []\n",
    "        for i in range(number_of_speakers):\n",
    "            #For each speaker initialize HP\n",
    "            speakers_states.append(tf.zeros((self.batch_size, self.D_p)))\n",
    "                \n",
    "        h_G = tf.zeros((self.batch_size, self.D_g))\n",
    "        \n",
    "        h_G_all = []\n",
    "        h_G_all.append(h_G)\n",
    "        \n",
    "        y_pred_prob_all = []\n",
    "        y_pred_all = []\n",
    "        #initialize emotion states\n",
    "        h_E = tf.zeros((self.batch_size, self.D_e))\n",
    "        \n",
    "        c = 0\n",
    "        #for each conversation in a batch \n",
    "        textual_representation = self.cnnTextualRepresentation(messages)\n",
    "            \n",
    "        for t_r, speaker in zip(textual_representation, speakers):\n",
    "            print(\"IN DIALOGUE RNN\")\n",
    "            print(speaker)\n",
    "            print(t_r.shape)\n",
    "\n",
    "            speakers_id = np.argmax(speaker)\n",
    "            print(\"speakers_id\")\n",
    "            print(speakers_id)\n",
    "            \n",
    "            if len(h_G_all)==1:\n",
    "                c_t = tf.zeros((self.batch_size, self.D_g))\n",
    "            else:\n",
    "                c_t = self.attention(h_G_all, t_r)\n",
    "\n",
    "            h_P_previous = speakers_states[speakers_id] \n",
    "            h_G = self.globalGRU(t_r, h_P_previous ,h_G)\n",
    "            h_G_all.append(h_G)\n",
    "\n",
    "            h_P = self.partyGRU(c_t, t_r, h_P_previous)\n",
    "            speakers_states[speakers_id] = h_P\n",
    "            print(speakers_states)\n",
    "\n",
    "            h_E =  self.emotionGRU(h_P, h_E)\n",
    "            y_pred_prob = self.classificationDense(h_E)\n",
    "            y_pred_prob =  tf.squeeze(y_pred_prob)\n",
    "            y_pred = np.argmax(y_pred_prob, axis=-1)\n",
    "\n",
    "            y_pred_prob_all.append(y_pred_prob)\n",
    "            y_pred_all.append(y_pred)\n",
    "            c = c+1\n",
    "\n",
    "        del speakers_states\n",
    "        del h_P_previous\n",
    "        del h_G\n",
    "        del h_G_all\n",
    "        del h_E\n",
    "        del t_r\n",
    "        del c_t\n",
    "        del h_P\n",
    "         \n",
    "\n",
    "        return y_pred_prob_all, y_pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "e174e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "n_epochs = 12\n",
    "\n",
    "D_g = 150\n",
    "D_p = 150\n",
    "D_e = 100\n",
    "D_c = 100\n",
    "\n",
    "n_classes=8\n",
    "glv_embedding_matrix = np.load(open('glv_embedding_matrix', 'rb') ,allow_pickle=True)\n",
    "vocab_size, embedding_dim = glv_embedding_matrix.shape\n",
    "cnn_output_size=100\n",
    "max_num_tokens = 250\n",
    "filters = 50\n",
    "kernel_sizes = [3,4,5]\n",
    "dropout = 0.5 \n",
    "\n",
    "dialogue_train_data['encoded_speaker']\n",
    "X = np.column_stack((dialogue_train_data['encoded_speaker'],dialogue_train_data['sequence']))\n",
    "y = dialogue_train_data['emotion_true'].values\n",
    "\n",
    "\n",
    "model = DialogueRNN(D_g, D_p, D_e, D_c, n_classes, vocab_size, embedding_dim, cnn_output_size , \n",
    "        max_num_tokens, glv_embedding_matrix, filters, kernel_sizes, dropout, batch_size)\n",
    "\n",
    "#model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              #loss=k.losses.CategoricalCrossentropy(from_logits=False, reduction='none'),\n",
    "              #metrics=k.metrics.Accuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "f374b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(x, max_len):   \n",
    "    \n",
    "    x = tf.cast(x, tf.float32)\n",
    "    x = x.to_tensor()\n",
    "    pad_size = list(x.shape)\n",
    "    pad_size[0] = max_len - x.shape[0]\n",
    "    x = tf.concat([x, tf.zeros(pad_size)], 0)\n",
    "        \n",
    "    return x\n",
    "\n",
    "def apply_padding(data):\n",
    "    # find longest sequence\n",
    "    new_batch = []\n",
    "        \n",
    "    for batch in data:\n",
    "        new_messages = []\n",
    "        new_speakers = []\n",
    "        new_y = []\n",
    "        max_len = max([sublist.shape[0] for sublist in batch[0]])\n",
    "        for index, res in enumerate(batch):\n",
    "            for i in res:\n",
    "                if index == 0:\n",
    "                    new_messages.append(pad_collate(i, max_len))\n",
    "                elif index == 1:\n",
    "                    new_speakers.append(pad_collate(i, max_len))\n",
    "                else:\n",
    "                    new_y.append(pad_collate(i, max_len))\n",
    "                    \n",
    "        new_messages = np.array(new_messages)\n",
    "        new_messages = tf.convert_to_tensor(np.transpose(new_messages, (1, 0, 2)))\n",
    "        new_speakers = np.array(new_speakers)\n",
    "        new_speakers = tf.convert_to_tensor(np.transpose(new_speakers, (1, 0, 2)))\n",
    "        new_y = np.array(new_y)\n",
    "        new_batch.append([new_messages, new_speakers, new_y])\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "465e52c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_batch(data, number_speakers, batch_size):\n",
    "    dialogue = dialogue_train_data[dialogue_train_data[\"speaker\"].apply(lambda x: len(set(x)) == number_speakers)]\n",
    "    \n",
    "    X = (dialogue['encoded_speaker'],dialogue['sequence'])\n",
    "    y = dialogue['emotion_true'].values\n",
    "\n",
    "    speakers=tf.ragged.constant(X[0])\n",
    "    dataset_speakers = tf.data.Dataset.from_tensor_slices(speakers)\n",
    "\n",
    "    messages=tf.ragged.constant(X[1])\n",
    "    dataset_messages = tf.data.Dataset.from_tensor_slices(messages)\n",
    "\n",
    "    y = tf.ragged.constant(y)\n",
    "    dataset_y = tf.data.Dataset.from_tensor_slices(y)\n",
    "    \n",
    "    dataset = tf.data.Dataset.zip((dataset_messages, dataset_speakers, dataset_y))\n",
    "    data = dataset.batch(batch_size, drop_remainder=True)\n",
    "    new_data = apply_padding(data)\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "8528c714",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For data lOADER\n",
      "(22, 8, 250)\n",
      "(22, 8, 2)\n",
      "number_of_speakers\n",
      "2\n",
      "(22, 8, 250)\n",
      "END TR SHAPE\n",
      "(176, 100)\n",
      "IN DIALOGUE RNN\n",
      "tf.Tensor(\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]], shape=(8, 2), dtype=float32)\n",
      "(8, 100)\n",
      "speakers_id\n",
      "1\n",
      "[<tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.991789  , 0.9409154 , 0.98429626, ..., 0.991518  , 0.9579719 ,\n",
      "        0.9783412 ],\n",
      "       [0.9918756 , 0.9394588 , 0.9838813 , ..., 0.9912841 , 0.95832807,\n",
      "        0.9776957 ],\n",
      "       [0.9918742 , 0.9394811 , 0.98388517, ..., 0.9912864 , 0.9583224 ,\n",
      "        0.9777008 ],\n",
      "       ...,\n",
      "       [0.9918494 , 0.9399093 , 0.984001  , ..., 0.99135095, 0.9582246 ,\n",
      "        0.9778837 ],\n",
      "       [0.9918579 , 0.9397752 , 0.9839699 , ..., 0.9913353 , 0.9582553 ,\n",
      "        0.9778382 ],\n",
      "       [0.9917723 , 0.94118005, 0.9843764 , ..., 0.991564  , 0.9579035 ,\n",
      "        0.9784656 ]], dtype=float32)>]\n",
      "IN DIALOGUE RNN\n",
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]], shape=(8, 2), dtype=float32)\n",
      "(8, 100)\n",
      "speakers_id\n",
      "0\n",
      "[<tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9918602 , 0.93973964, 0.9839621 , ..., 0.9913299 , 0.958266  ,\n",
      "        0.9778276 ],\n",
      "       [0.99187404, 0.939509  , 0.98390526, ..., 0.99129754, 0.95832026,\n",
      "        0.97773963],\n",
      "       [0.9918091 , 0.94057095, 0.984188  , ..., 0.9914556 , 0.95806104,\n",
      "        0.9781716 ],\n",
      "       ...,\n",
      "       [0.9918213 , 0.9403784 , 0.9841303 , ..., 0.9914245 , 0.9581091 ,\n",
      "        0.9780834 ],\n",
      "       [0.99181736, 0.9405113 , 0.98422277, ..., 0.99147576, 0.95808023,\n",
      "        0.97824526],\n",
      "       [0.9918002 , 0.94077116, 0.9842833 , ..., 0.9915122 , 0.95801115,\n",
      "        0.97833514]], dtype=float32)>, <tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.991789  , 0.9409154 , 0.98429626, ..., 0.991518  , 0.9579719 ,\n",
      "        0.9783412 ],\n",
      "       [0.9918756 , 0.9394588 , 0.9838813 , ..., 0.9912841 , 0.95832807,\n",
      "        0.9776957 ],\n",
      "       [0.9918742 , 0.9394811 , 0.98388517, ..., 0.9912864 , 0.9583224 ,\n",
      "        0.9777008 ],\n",
      "       ...,\n",
      "       [0.9918494 , 0.9399093 , 0.984001  , ..., 0.99135095, 0.9582246 ,\n",
      "        0.9778837 ],\n",
      "       [0.9918579 , 0.9397752 , 0.9839699 , ..., 0.9913353 , 0.9582553 ,\n",
      "        0.9778382 ],\n",
      "       [0.9917723 , 0.94118005, 0.9843764 , ..., 0.991564  , 0.9579035 ,\n",
      "        0.9784656 ]], dtype=float32)>]\n",
      "IN DIALOGUE RNN\n",
      "tf.Tensor(\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]], shape=(8, 2), dtype=float32)\n",
      "(8, 100)\n",
      "speakers_id\n",
      "1\n",
      "[<tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9918602 , 0.93973964, 0.9839621 , ..., 0.9913299 , 0.958266  ,\n",
      "        0.9778276 ],\n",
      "       [0.99187404, 0.939509  , 0.98390526, ..., 0.99129754, 0.95832026,\n",
      "        0.97773963],\n",
      "       [0.9918091 , 0.94057095, 0.984188  , ..., 0.9914556 , 0.95806104,\n",
      "        0.9781716 ],\n",
      "       ...,\n",
      "       [0.9918213 , 0.9403784 , 0.9841303 , ..., 0.9914245 , 0.9581091 ,\n",
      "        0.9780834 ],\n",
      "       [0.99181736, 0.9405113 , 0.98422277, ..., 0.99147576, 0.95808023,\n",
      "        0.97824526],\n",
      "       [0.9918002 , 0.94077116, 0.9842833 , ..., 0.9915122 , 0.95801115,\n",
      "        0.97833514]], dtype=float32)>, <tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.99178195, 0.9410654 , 0.9843486 , ..., 0.99154747, 0.95793617,\n",
      "        0.97841704],\n",
      "       [0.9918053 , 0.94070435, 0.98425335, ..., 0.9914921 , 0.9580402 ,\n",
      "        0.97828346],\n",
      "       [0.991795  , 0.9408374 , 0.9842862 , ..., 0.9915102 , 0.957994  ,\n",
      "        0.97832084],\n",
      "       ...,\n",
      "       [0.99180126, 0.9407484 , 0.9842742 , ..., 0.99150234, 0.95801735,\n",
      "        0.9783062 ],\n",
      "       [0.99179685, 0.9408607 , 0.98433495, ..., 0.9915399 , 0.9579762 ,\n",
      "        0.9783982 ],\n",
      "       [0.99187386, 0.93951327, 0.98390424, ..., 0.991294  , 0.9583206 ,\n",
      "        0.9777264 ]], dtype=float32)>]\n",
      "IN DIALOGUE RNN\n",
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]], shape=(8, 2), dtype=float32)\n",
      "(8, 100)\n",
      "speakers_id\n",
      "0\n",
      "[<tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9918195 , 0.9405502 , 0.98425627, ..., 0.9914929 , 0.95806   ,\n",
      "        0.97827405],\n",
      "       [0.9918499 , 0.9399248 , 0.9840131 , ..., 0.9913544 , 0.9582272 ,\n",
      "        0.9778982 ],\n",
      "       [0.99178374, 0.9410064 , 0.98432535, ..., 0.99153155, 0.9579505 ,\n",
      "        0.9783762 ],\n",
      "       ...,\n",
      "       [0.9918263 , 0.94032776, 0.984133  , ..., 0.9914242 , 0.9581267 ,\n",
      "        0.97808754],\n",
      "       [0.99182314, 0.9403999 , 0.9841571 , ..., 0.99143785, 0.95811564,\n",
      "        0.9781319 ],\n",
      "       [0.99181944, 0.94046867, 0.9842011 , ..., 0.991461  , 0.95808893,\n",
      "        0.9781954 ]], dtype=float32)>, <tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.99178195, 0.9410654 , 0.9843486 , ..., 0.99154747, 0.95793617,\n",
      "        0.97841704],\n",
      "       [0.9918053 , 0.94070435, 0.98425335, ..., 0.9914921 , 0.9580402 ,\n",
      "        0.97828346],\n",
      "       [0.991795  , 0.9408374 , 0.9842862 , ..., 0.9915102 , 0.957994  ,\n",
      "        0.97832084],\n",
      "       ...,\n",
      "       [0.99180126, 0.9407484 , 0.9842742 , ..., 0.99150234, 0.95801735,\n",
      "        0.9783062 ],\n",
      "       [0.99179685, 0.9408607 , 0.98433495, ..., 0.9915399 , 0.9579762 ,\n",
      "        0.9783982 ],\n",
      "       [0.99187386, 0.93951327, 0.98390424, ..., 0.991294  , 0.9583206 ,\n",
      "        0.9777264 ]], dtype=float32)>]\n",
      "IN DIALOGUE RNN\n",
      "tf.Tensor(\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]], shape=(8, 2), dtype=float32)\n",
      "(8, 100)\n",
      "speakers_id\n",
      "1\n",
      "[<tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9918195 , 0.9405502 , 0.98425627, ..., 0.9914929 , 0.95806   ,\n",
      "        0.97827405],\n",
      "       [0.9918499 , 0.9399248 , 0.9840131 , ..., 0.9913544 , 0.9582272 ,\n",
      "        0.9778982 ],\n",
      "       [0.99178374, 0.9410064 , 0.98432535, ..., 0.99153155, 0.9579505 ,\n",
      "        0.9783762 ],\n",
      "       ...,\n",
      "       [0.9918263 , 0.94032776, 0.984133  , ..., 0.9914242 , 0.9581267 ,\n",
      "        0.97808754],\n",
      "       [0.99182314, 0.9403999 , 0.9841571 , ..., 0.99143785, 0.95811564,\n",
      "        0.9781319 ],\n",
      "       [0.99181944, 0.94046867, 0.9842011 , ..., 0.991461  , 0.95808893,\n",
      "        0.9781954 ]], dtype=float32)>, <tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9918047 , 0.94070524, 0.98428494, ..., 0.99150985, 0.9580125 ,\n",
      "        0.97831583],\n",
      "       [0.991879  , 0.93942124, 0.9838777 , ..., 0.99127805, 0.95834166,\n",
      "        0.9776822 ],\n",
      "       [0.9918047 , 0.9407519 , 0.9843052 , ..., 0.9915215 , 0.958003  ,\n",
      "        0.9783462 ],\n",
      "       ...,\n",
      "       [0.9918541 , 0.9398581 , 0.9839956 , ..., 0.99134576, 0.95824116,\n",
      "        0.97787064],\n",
      "       [0.9918754 , 0.9394895 , 0.9838987 , ..., 0.9912904 , 0.95832694,\n",
      "        0.97771764],\n",
      "       [0.9918155 , 0.94050866, 0.98419064, ..., 0.9914554 , 0.95808184,\n",
      "        0.9781765 ]], dtype=float32)>]\n",
      "IN DIALOGUE RNN\n",
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]], shape=(8, 2), dtype=float32)\n",
      "(8, 100)\n",
      "speakers_id\n",
      "0\n",
      "[<tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9918031 , 0.94076633, 0.98429656, ..., 0.991515  , 0.9580167 ,\n",
      "        0.97834665],\n",
      "       [0.99185133, 0.93992734, 0.98402804, ..., 0.9913651 , 0.958226  ,\n",
      "        0.9779278 ],\n",
      "       [0.9917982 , 0.94076806, 0.98424995, ..., 0.9914895 , 0.9580054 ,\n",
      "        0.9782522 ],\n",
      "       ...,\n",
      "       [0.9918741 , 0.939503  , 0.98389834, ..., 0.99129057, 0.95832187,\n",
      "        0.9777148 ],\n",
      "       [0.9917922 , 0.9408804 , 0.98432624, ..., 0.9915301 , 0.95797294,\n",
      "        0.9783774 ],\n",
      "       [0.9918465 , 0.94001937, 0.9840514 , ..., 0.9913776 , 0.9582082 ,\n",
      "        0.97796655]], dtype=float32)>, <tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9918047 , 0.94070524, 0.98428494, ..., 0.99150985, 0.9580125 ,\n",
      "        0.97831583],\n",
      "       [0.991879  , 0.93942124, 0.9838777 , ..., 0.99127805, 0.95834166,\n",
      "        0.9776822 ],\n",
      "       [0.9918047 , 0.9407519 , 0.9843052 , ..., 0.9915215 , 0.958003  ,\n",
      "        0.9783462 ],\n",
      "       ...,\n",
      "       [0.9918541 , 0.9398581 , 0.9839956 , ..., 0.99134576, 0.95824116,\n",
      "        0.97787064],\n",
      "       [0.9918754 , 0.9394895 , 0.9838987 , ..., 0.9912904 , 0.95832694,\n",
      "        0.97771764],\n",
      "       [0.9918155 , 0.94050866, 0.98419064, ..., 0.9914554 , 0.95808184,\n",
      "        0.9781765 ]], dtype=float32)>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN DIALOGUE RNN\n",
      "tf.Tensor(\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]], shape=(8, 2), dtype=float32)\n",
      "(8, 100)\n",
      "speakers_id\n",
      "1\n",
      "[<tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9918031 , 0.94076633, 0.98429656, ..., 0.991515  , 0.9580167 ,\n",
      "        0.97834665],\n",
      "       [0.99185133, 0.93992734, 0.98402804, ..., 0.9913651 , 0.958226  ,\n",
      "        0.9779278 ],\n",
      "       [0.9917982 , 0.94076806, 0.98424995, ..., 0.9914895 , 0.9580054 ,\n",
      "        0.9782522 ],\n",
      "       ...,\n",
      "       [0.9918741 , 0.939503  , 0.98389834, ..., 0.99129057, 0.95832187,\n",
      "        0.9777148 ],\n",
      "       [0.9917922 , 0.9408804 , 0.98432624, ..., 0.9915301 , 0.95797294,\n",
      "        0.9783774 ],\n",
      "       [0.9918465 , 0.94001937, 0.9840514 , ..., 0.9913776 , 0.9582082 ,\n",
      "        0.97796655]], dtype=float32)>, <tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9918251 , 0.94040364, 0.98418665, ..., 0.99145377, 0.9581118 ,\n",
      "        0.9781813 ],\n",
      "       [0.9918323 , 0.94029033, 0.9841784 , ..., 0.9914483 , 0.95813596,\n",
      "        0.9781715 ],\n",
      "       [0.9918848 , 0.93928325, 0.9838235 , ..., 0.9912473 , 0.9583652 ,\n",
      "        0.97758305],\n",
      "       ...,\n",
      "       [0.9917829 , 0.94099736, 0.9843275 , ..., 0.9915326 , 0.9579411 ,\n",
      "        0.9783707 ],\n",
      "       [0.99180937, 0.94068104, 0.98428077, ..., 0.99150777, 0.9580236 ,\n",
      "        0.9783092 ],\n",
      "       [0.9918336 , 0.9403725 , 0.98423755, ..., 0.9914826 , 0.9581137 ,\n",
      "        0.9782634 ]], dtype=float32)>]\n",
      "IN DIALOGUE RNN\n",
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [0. 1.]], shape=(8, 2), dtype=float32)\n",
      "(8, 100)\n",
      "speakers_id\n",
      "0\n",
      "[<tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9918038 , 0.9407276 , 0.9842644 , ..., 0.99149764, 0.95802534,\n",
      "        0.97829175],\n",
      "       [0.9917927 , 0.9408888 , 0.9843308 , ..., 0.99153435, 0.95796233,\n",
      "        0.97837603],\n",
      "       [0.9918854 , 0.9392828 , 0.983824  , ..., 0.99124765, 0.9583652 ,\n",
      "        0.97758275],\n",
      "       ...,\n",
      "       [0.9917948 , 0.94087535, 0.98432624, ..., 0.99153453, 0.9579704 ,\n",
      "        0.978378  ],\n",
      "       [0.9918854 , 0.9392828 , 0.983824  , ..., 0.99124765, 0.9583653 ,\n",
      "        0.97758275],\n",
      "       [0.9918624 , 0.9397594 , 0.9839889 , ..., 0.9913424 , 0.9582673 ,\n",
      "        0.9778676 ]], dtype=float32)>, <tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9918251 , 0.94040364, 0.98418665, ..., 0.99145377, 0.9581118 ,\n",
      "        0.9781813 ],\n",
      "       [0.9918323 , 0.94029033, 0.9841784 , ..., 0.9914483 , 0.95813596,\n",
      "        0.9781715 ],\n",
      "       [0.9918848 , 0.93928325, 0.9838235 , ..., 0.9912473 , 0.9583652 ,\n",
      "        0.97758305],\n",
      "       ...,\n",
      "       [0.9917829 , 0.94099736, 0.9843275 , ..., 0.9915326 , 0.9579411 ,\n",
      "        0.9783707 ],\n",
      "       [0.99180937, 0.94068104, 0.98428077, ..., 0.99150777, 0.9580236 ,\n",
      "        0.9783092 ],\n",
      "       [0.9918336 , 0.9403725 , 0.98423755, ..., 0.9914826 , 0.9581137 ,\n",
      "        0.9782634 ]], dtype=float32)>]\n",
      "IN DIALOGUE RNN\n",
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [0. 1.]], shape=(8, 2), dtype=float32)\n",
      "(8, 100)\n",
      "speakers_id\n",
      "0\n",
      "[<tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.99187434, 0.93951285, 0.98390704, ..., 0.99129546, 0.9583217 ,\n",
      "        0.97773206],\n",
      "       [0.9918083 , 0.94061625, 0.9842138 , ..., 0.9914693 , 0.9580485 ,\n",
      "        0.9782045 ],\n",
      "       [0.99188495, 0.93928325, 0.98382354, ..., 0.9912473 , 0.9583652 ,\n",
      "        0.97758293],\n",
      "       ...,\n",
      "       [0.991838  , 0.9403363 , 0.98420477, ..., 0.9914644 , 0.95812875,\n",
      "        0.97818893],\n",
      "       [0.99188495, 0.93928325, 0.9838235 , ..., 0.9912473 , 0.9583652 ,\n",
      "        0.97758293],\n",
      "       [0.99181587, 0.9405437 , 0.9842074 , ..., 0.9914649 , 0.95807964,\n",
      "        0.9782086 ]], dtype=float32)>, <tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9918251 , 0.94040364, 0.98418665, ..., 0.99145377, 0.9581118 ,\n",
      "        0.9781813 ],\n",
      "       [0.9918323 , 0.94029033, 0.9841784 , ..., 0.9914483 , 0.95813596,\n",
      "        0.9781715 ],\n",
      "       [0.9918848 , 0.93928325, 0.9838235 , ..., 0.9912473 , 0.9583652 ,\n",
      "        0.97758305],\n",
      "       ...,\n",
      "       [0.9917829 , 0.94099736, 0.9843275 , ..., 0.9915326 , 0.9579411 ,\n",
      "        0.9783707 ],\n",
      "       [0.99180937, 0.94068104, 0.98428077, ..., 0.99150777, 0.9580236 ,\n",
      "        0.9783092 ],\n",
      "       [0.9918336 , 0.9403725 , 0.98423755, ..., 0.9914826 , 0.9581137 ,\n",
      "        0.9782634 ]], dtype=float32)>]\n",
      "IN DIALOGUE RNN\n",
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 0.]\n",
      " [0. 1.]], shape=(8, 2), dtype=float32)\n",
      "(8, 100)\n",
      "speakers_id\n",
      "0\n",
      "[<tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.99180615, 0.9407302 , 0.9843026 , ..., 0.9915216 , 0.95800525,\n",
      "        0.9783437 ],\n",
      "       [0.99185634, 0.9398418 , 0.9840058 , ..., 0.99135244, 0.95824736,\n",
      "        0.9778942 ],\n",
      "       [0.9918848 , 0.93928325, 0.9838233 , ..., 0.9912473 , 0.9583652 ,\n",
      "        0.9775834 ],\n",
      "       ...,\n",
      "       [0.9918293 , 0.94026446, 0.9840992 , ..., 0.99140316, 0.9581403 ,\n",
      "        0.97802424],\n",
      "       [0.99188495, 0.93928325, 0.9838233 , ..., 0.9912473 , 0.9583652 ,\n",
      "        0.9775834 ],\n",
      "       [0.9917719 , 0.94117934, 0.9843961 , ..., 0.9915685 , 0.95789766,\n",
      "        0.9784802 ]], dtype=float32)>, <tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9918251 , 0.94040364, 0.98418665, ..., 0.99145377, 0.9581118 ,\n",
      "        0.9781813 ],\n",
      "       [0.9918323 , 0.94029033, 0.9841784 , ..., 0.9914483 , 0.95813596,\n",
      "        0.9781715 ],\n",
      "       [0.9918848 , 0.93928325, 0.9838235 , ..., 0.9912473 , 0.9583652 ,\n",
      "        0.97758305],\n",
      "       ...,\n",
      "       [0.9917829 , 0.94099736, 0.9843275 , ..., 0.9915326 , 0.9579411 ,\n",
      "        0.9783707 ],\n",
      "       [0.99180937, 0.94068104, 0.98428077, ..., 0.99150777, 0.9580236 ,\n",
      "        0.9783092 ],\n",
      "       [0.9918336 , 0.9403725 , 0.98423755, ..., 0.9914826 , 0.9581137 ,\n",
      "        0.9782634 ]], dtype=float32)>]\n",
      "IN DIALOGUE RNN\n",
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [0. 1.]], shape=(8, 2), dtype=float32)\n",
      "(8, 100)\n",
      "speakers_id\n",
      "0\n",
      "[<tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.99185956, 0.9397801 , 0.98397696, ..., 0.99133605, 0.9582586 ,\n",
      "        0.97784096],\n",
      "       [0.99179536, 0.94091815, 0.98432523, ..., 0.9915303 , 0.9579792 ,\n",
      "        0.97837734],\n",
      "       [0.9918859 , 0.93928254, 0.9838242 , ..., 0.9912478 , 0.9583658 ,\n",
      "        0.97758293],\n",
      "       ...,\n",
      "       [0.99179465, 0.94091725, 0.9843267 , ..., 0.9915314 , 0.95798403,\n",
      "        0.97839093],\n",
      "       [0.99188584, 0.93928254, 0.98382425, ..., 0.9912478 , 0.9583658 ,\n",
      "        0.97758293],\n",
      "       [0.99182826, 0.9403544 , 0.9841539 , ..., 0.99143624, 0.9581212 ,\n",
      "        0.97812   ]], dtype=float32)>, <tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9918251 , 0.94040364, 0.98418665, ..., 0.99145377, 0.9581118 ,\n",
      "        0.9781813 ],\n",
      "       [0.9918323 , 0.94029033, 0.9841784 , ..., 0.9914483 , 0.95813596,\n",
      "        0.9781715 ],\n",
      "       [0.9918848 , 0.93928325, 0.9838235 , ..., 0.9912473 , 0.9583652 ,\n",
      "        0.97758305],\n",
      "       ...,\n",
      "       [0.9917829 , 0.94099736, 0.9843275 , ..., 0.9915326 , 0.9579411 ,\n",
      "        0.9783707 ],\n",
      "       [0.99180937, 0.94068104, 0.98428077, ..., 0.99150777, 0.9580236 ,\n",
      "        0.9783092 ],\n",
      "       [0.9918336 , 0.9403725 , 0.98423755, ..., 0.9914826 , 0.9581137 ,\n",
      "        0.9782634 ]], dtype=float32)>]\n",
      "IN DIALOGUE RNN\n",
      "tf.Tensor(\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 0.]\n",
      " [1. 0.]], shape=(8, 2), dtype=float32)\n",
      "(8, 100)\n",
      "speakers_id\n",
      "1\n",
      "[<tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.99185956, 0.9397801 , 0.98397696, ..., 0.99133605, 0.9582586 ,\n",
      "        0.97784096],\n",
      "       [0.99179536, 0.94091815, 0.98432523, ..., 0.9915303 , 0.9579792 ,\n",
      "        0.97837734],\n",
      "       [0.9918859 , 0.93928254, 0.9838242 , ..., 0.9912478 , 0.9583658 ,\n",
      "        0.97758293],\n",
      "       ...,\n",
      "       [0.99179465, 0.94091725, 0.9843267 , ..., 0.9915314 , 0.95798403,\n",
      "        0.97839093],\n",
      "       [0.99188584, 0.93928254, 0.98382425, ..., 0.9912478 , 0.9583658 ,\n",
      "        0.97758293],\n",
      "       [0.99182826, 0.9403544 , 0.9841539 , ..., 0.99143624, 0.9581212 ,\n",
      "        0.97812   ]], dtype=float32)>, <tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9917999 , 0.94076514, 0.9842531 , ..., 0.99148965, 0.9580207 ,\n",
      "        0.97826946],\n",
      "       [0.99179155, 0.94097155, 0.98433137, ..., 0.9915332 , 0.9579649 ,\n",
      "        0.97838056],\n",
      "       [0.99188495, 0.9392832 , 0.98382354, ..., 0.9912473 , 0.9583652 ,\n",
      "        0.97758293],\n",
      "       ...,\n",
      "       [0.99182606, 0.94039583, 0.9841577 , ..., 0.99143696, 0.95811325,\n",
      "        0.9781214 ],\n",
      "       [0.99188495, 0.93928313, 0.98382354, ..., 0.9912473 , 0.9583652 ,\n",
      "        0.97758293],\n",
      "       [0.99182796, 0.94043076, 0.9842332 , ..., 0.99148184, 0.95809335,\n",
      "        0.9782489 ]], dtype=float32)>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN DIALOGUE RNN\n",
      "tf.Tensor(\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]], shape=(8, 2), dtype=float32)\n",
      "(8, 100)\n",
      "speakers_id\n",
      "1\n",
      "[<tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.99185956, 0.9397801 , 0.98397696, ..., 0.99133605, 0.9582586 ,\n",
      "        0.97784096],\n",
      "       [0.99179536, 0.94091815, 0.98432523, ..., 0.9915303 , 0.9579792 ,\n",
      "        0.97837734],\n",
      "       [0.9918859 , 0.93928254, 0.9838242 , ..., 0.9912478 , 0.9583658 ,\n",
      "        0.97758293],\n",
      "       ...,\n",
      "       [0.99179465, 0.94091725, 0.9843267 , ..., 0.9915314 , 0.95798403,\n",
      "        0.97839093],\n",
      "       [0.99188584, 0.93928254, 0.98382425, ..., 0.9912478 , 0.9583658 ,\n",
      "        0.97758293],\n",
      "       [0.99182826, 0.9403544 , 0.9841539 , ..., 0.99143624, 0.9581212 ,\n",
      "        0.97812   ]], dtype=float32)>, <tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9918565 , 0.93990874, 0.9840259 , ..., 0.9913645 , 0.95823395,\n",
      "        0.9779224 ],\n",
      "       [0.99187684, 0.9394884 , 0.98389995, ..., 0.9912909 , 0.9583272 ,\n",
      "        0.97771734],\n",
      "       [0.9918861 , 0.93928236, 0.98382443, ..., 0.9912478 , 0.9583658 ,\n",
      "        0.9775826 ],\n",
      "       ...,\n",
      "       [0.99181044, 0.9407143 , 0.98428416, ..., 0.9915105 , 0.9580223 ,\n",
      "        0.97830397],\n",
      "       [0.9918861 , 0.93928236, 0.98382443, ..., 0.9912478 , 0.9583658 ,\n",
      "        0.9775826 ],\n",
      "       [0.9918861 , 0.9392823 , 0.98382443, ..., 0.9912478 , 0.9583658 ,\n",
      "        0.9775826 ]], dtype=float32)>]\n",
      "IN DIALOGUE RNN\n",
      "tf.Tensor(\n",
      "[[0. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]], shape=(8, 2), dtype=float32)\n",
      "(8, 100)\n",
      "speakers_id\n",
      "1\n",
      "[<tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.99185956, 0.9397801 , 0.98397696, ..., 0.99133605, 0.9582586 ,\n",
      "        0.97784096],\n",
      "       [0.99179536, 0.94091815, 0.98432523, ..., 0.9915303 , 0.9579792 ,\n",
      "        0.97837734],\n",
      "       [0.9918859 , 0.93928254, 0.9838242 , ..., 0.9912478 , 0.9583658 ,\n",
      "        0.97758293],\n",
      "       ...,\n",
      "       [0.99179465, 0.94091725, 0.9843267 , ..., 0.9915314 , 0.95798403,\n",
      "        0.97839093],\n",
      "       [0.99188584, 0.93928254, 0.98382425, ..., 0.9912478 , 0.9583658 ,\n",
      "        0.97758293],\n",
      "       [0.99182826, 0.9403544 , 0.9841539 , ..., 0.99143624, 0.9581212 ,\n",
      "        0.97812   ]], dtype=float32)>, <tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.99187213, 0.9396171 , 0.9839334 , ..., 0.99131024, 0.95829856,\n",
      "        0.97776496],\n",
      "       [0.9918875 , 0.93928117, 0.98382545, ..., 0.99124825, 0.9583666 ,\n",
      "        0.977582  ],\n",
      "       [0.99188745, 0.93928117, 0.98382556, ..., 0.9912482 , 0.9583666 ,\n",
      "        0.977582  ],\n",
      "       ...,\n",
      "       [0.9918784 , 0.93948734, 0.98390096, ..., 0.9912914 , 0.95832807,\n",
      "        0.9777165 ],\n",
      "       [0.99188745, 0.9392812 , 0.98382556, ..., 0.99124825, 0.9583665 ,\n",
      "        0.977582  ],\n",
      "       [0.99188745, 0.93928117, 0.98382545, ..., 0.99124825, 0.9583665 ,\n",
      "        0.977582  ]], dtype=float32)>]\n",
      "IN DIALOGUE RNN\n",
      "tf.Tensor(\n",
      "[[0. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]], shape=(8, 2), dtype=float32)\n",
      "(8, 100)\n",
      "speakers_id\n",
      "1\n",
      "[<tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.99185956, 0.9397801 , 0.98397696, ..., 0.99133605, 0.9582586 ,\n",
      "        0.97784096],\n",
      "       [0.99179536, 0.94091815, 0.98432523, ..., 0.9915303 , 0.9579792 ,\n",
      "        0.97837734],\n",
      "       [0.9918859 , 0.93928254, 0.9838242 , ..., 0.9912478 , 0.9583658 ,\n",
      "        0.97758293],\n",
      "       ...,\n",
      "       [0.99179465, 0.94091725, 0.9843267 , ..., 0.9915314 , 0.95798403,\n",
      "        0.97839093],\n",
      "       [0.99188584, 0.93928254, 0.98382425, ..., 0.9912478 , 0.9583658 ,\n",
      "        0.97758293],\n",
      "       [0.99182826, 0.9403544 , 0.9841539 , ..., 0.99143624, 0.9581212 ,\n",
      "        0.97812   ]], dtype=float32)>, <tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.99180096, 0.9408539 , 0.9843248 , ..., 0.99154073, 0.95798427,\n",
      "        0.9783365 ],\n",
      "       [0.99188596, 0.93928236, 0.9838245 , ..., 0.9912478 , 0.9583658 ,\n",
      "        0.9775826 ],\n",
      "       [0.99188596, 0.9392824 , 0.9838244 , ..., 0.9912478 , 0.9583658 ,\n",
      "        0.9775826 ],\n",
      "       ...,\n",
      "       [0.99180543, 0.9407104 , 0.98427397, ..., 0.99150056, 0.9580309 ,\n",
      "        0.9783082 ],\n",
      "       [0.99188596, 0.9392824 , 0.98382443, ..., 0.9912478 , 0.9583658 ,\n",
      "        0.9775826 ],\n",
      "       [0.99188596, 0.93928236, 0.98382443, ..., 0.9912478 , 0.9583658 ,\n",
      "        0.9775826 ]], dtype=float32)>]\n",
      "IN DIALOGUE RNN\n",
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]], shape=(8, 2), dtype=float32)\n",
      "(8, 100)\n",
      "speakers_id\n",
      "0\n",
      "[<tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9918184 , 0.94057256, 0.98423946, ..., 0.9914847 , 0.95806736,\n",
      "        0.9782542 ],\n",
      "       [0.9918871 , 0.9392816 , 0.98382515, ..., 0.99124795, 0.958366  ,\n",
      "        0.97758216],\n",
      "       [0.991887  , 0.93928164, 0.98382515, ..., 0.99124783, 0.9583659 ,\n",
      "        0.97758216],\n",
      "       ...,\n",
      "       [0.9918535 , 0.94002354, 0.98406065, ..., 0.991385  , 0.95821315,\n",
      "        0.97797036],\n",
      "       [0.991887  , 0.9392816 , 0.98382515, ..., 0.99124783, 0.9583659 ,\n",
      "        0.97758216],\n",
      "       [0.991887  , 0.9392816 , 0.9838252 , ..., 0.99124783, 0.9583659 ,\n",
      "        0.97758216]], dtype=float32)>, <tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.99180096, 0.9408539 , 0.9843248 , ..., 0.99154073, 0.95798427,\n",
      "        0.9783365 ],\n",
      "       [0.99188596, 0.93928236, 0.9838245 , ..., 0.9912478 , 0.9583658 ,\n",
      "        0.9775826 ],\n",
      "       [0.99188596, 0.9392824 , 0.9838244 , ..., 0.9912478 , 0.9583658 ,\n",
      "        0.9775826 ],\n",
      "       ...,\n",
      "       [0.99180543, 0.9407104 , 0.98427397, ..., 0.99150056, 0.9580309 ,\n",
      "        0.9783082 ],\n",
      "       [0.99188596, 0.9392824 , 0.98382443, ..., 0.9912478 , 0.9583658 ,\n",
      "        0.9775826 ],\n",
      "       [0.99188596, 0.93928236, 0.98382443, ..., 0.9912478 , 0.9583658 ,\n",
      "        0.9775826 ]], dtype=float32)>]\n",
      "IN DIALOGUE RNN\n",
      "tf.Tensor(\n",
      "[[0. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]], shape=(8, 2), dtype=float32)\n",
      "(8, 100)\n",
      "speakers_id\n",
      "1\n",
      "[<tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9918184 , 0.94057256, 0.98423946, ..., 0.9914847 , 0.95806736,\n",
      "        0.9782542 ],\n",
      "       [0.9918871 , 0.9392816 , 0.98382515, ..., 0.99124795, 0.958366  ,\n",
      "        0.97758216],\n",
      "       [0.991887  , 0.93928164, 0.98382515, ..., 0.99124783, 0.9583659 ,\n",
      "        0.97758216],\n",
      "       ...,\n",
      "       [0.9918535 , 0.94002354, 0.98406065, ..., 0.991385  , 0.95821315,\n",
      "        0.97797036],\n",
      "       [0.991887  , 0.9392816 , 0.98382515, ..., 0.99124783, 0.9583659 ,\n",
      "        0.97758216],\n",
      "       [0.991887  , 0.9392816 , 0.9838252 , ..., 0.99124783, 0.9583659 ,\n",
      "        0.97758216]], dtype=float32)>, <tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9917997 , 0.94089454, 0.9843091 , ..., 0.99152595, 0.9579903 ,\n",
      "        0.97835153],\n",
      "       [0.9918877 , 0.93928117, 0.98382556, ..., 0.99124825, 0.95836663,\n",
      "        0.977582  ],\n",
      "       [0.9918877 , 0.93928105, 0.98382556, ..., 0.99124825, 0.95836663,\n",
      "        0.977582  ],\n",
      "       ...,\n",
      "       [0.9918877 , 0.93928105, 0.98382556, ..., 0.99124825, 0.95836663,\n",
      "        0.977582  ],\n",
      "       [0.9918877 , 0.93928105, 0.98382556, ..., 0.99124825, 0.95836663,\n",
      "        0.977582  ],\n",
      "       [0.9918877 , 0.93928105, 0.98382556, ..., 0.99124825, 0.95836663,\n",
      "        0.977582  ]], dtype=float32)>]\n",
      "IN DIALOGUE RNN\n",
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]], shape=(8, 2), dtype=float32)\n",
      "(8, 100)\n",
      "speakers_id\n",
      "0\n",
      "[<tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.99180865, 0.9406495 , 0.98426396, ..., 0.9914937 , 0.958034  ,\n",
      "        0.97827804],\n",
      "       [0.9918884 , 0.9392804 , 0.98382604, ..., 0.9912483 , 0.9583672 ,\n",
      "        0.9775814 ],\n",
      "       [0.9918884 , 0.9392804 , 0.98382604, ..., 0.9912483 , 0.9583672 ,\n",
      "        0.9775814 ],\n",
      "       ...,\n",
      "       [0.99188846, 0.93928045, 0.98382604, ..., 0.9912483 , 0.95836735,\n",
      "        0.9775814 ],\n",
      "       [0.99188846, 0.9392804 , 0.98382604, ..., 0.9912483 , 0.9583672 ,\n",
      "        0.97758144],\n",
      "       [0.99188846, 0.9392804 , 0.98382604, ..., 0.9912483 , 0.9583672 ,\n",
      "        0.97758144]], dtype=float32)>, <tf.Tensor: shape=(8, 150), dtype=float32, numpy=\n",
      "array([[0.9917997 , 0.94089454, 0.9843091 , ..., 0.99152595, 0.9579903 ,\n",
      "        0.97835153],\n",
      "       [0.9918877 , 0.93928117, 0.98382556, ..., 0.99124825, 0.95836663,\n",
      "        0.977582  ],\n",
      "       [0.9918877 , 0.93928105, 0.98382556, ..., 0.99124825, 0.95836663,\n",
      "        0.977582  ],\n",
      "       ...,\n",
      "       [0.9918877 , 0.93928105, 0.98382556, ..., 0.99124825, 0.95836663,\n",
      "        0.977582  ],\n",
      "       [0.9918877 , 0.93928105, 0.98382556, ..., 0.99124825, 0.95836663,\n",
      "        0.977582  ],\n",
      "       [0.9918877 , 0.93928105, 0.98382556, ..., 0.99124825, 0.95836663,\n",
      "        0.977582  ]], dtype=float32)>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN DIALOGUE RNN\n",
      "tf.Tensor(\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]], shape=(8, 2), dtype=float32)\n",
      "(8, 100)\n",
      "speakers_id\n",
      "8\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Exception encountered when calling layer \"dialogue_rnn_11\" (type DialogueRNN).\n\nlist index out of range\n\nCall arguments received:\n  • messages=tf.Tensor(shape=(22, 8, 250), dtype=float32)\n  • speakers=tf.Tensor(shape=(22, 8, 2), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [479]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(messages\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(speakers\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 43\u001b[0m loss_value, grads \u001b[38;5;241m=\u001b[39m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeakers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#print(grads)\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m#print(\"Step: {}, Initial Loss: {}\".format(optimizer.iterations.numpy(),\u001b[39;00m\n\u001b[0;32m     46\u001b[0m                                   \u001b[38;5;66;03m#loss_value.numpy()))\u001b[39;00m\n\u001b[0;32m     47\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Input \u001b[1;32mIn [479]\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(model, messages, speakers, y)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad\u001b[39m(model, messages, speakers, y):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m---> 14\u001b[0m         loss_value \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeakers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;66;03m#print([var.name for var in tape.watched_variables()])\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_value, tape\u001b[38;5;241m.\u001b[39mgradient(loss_value, model\u001b[38;5;241m.\u001b[39mtrainable_variables\n\u001b[0;32m     18\u001b[0m                                      \u001b[38;5;66;03m#unconnected_gradients=tf.UnconnectedGradients.ZERO\u001b[39;00m\n\u001b[0;32m     19\u001b[0m )\n",
      "Input \u001b[1;32mIn [479]\u001b[0m, in \u001b[0;36mloss\u001b[1;34m(model, messages, speakers, y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(model, messages, speakers, y):\n\u001b[0;32m      2\u001b[0m     loss_object \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m     y_pred_prob_all, y_pred_all \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeakers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y_pred_all)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m#y = np.transpose(y, (1, 0, 2))\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Input \u001b[1;32mIn [475]\u001b[0m, in \u001b[0;36mDialogueRNN.call\u001b[1;34m(self, messages, speakers)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     c_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(h_G_all, t_r)\n\u001b[1;32m---> 61\u001b[0m h_P_previous \u001b[38;5;241m=\u001b[39m \u001b[43mspeakers_states\u001b[49m\u001b[43m[\u001b[49m\u001b[43mspeakers_id\u001b[49m\u001b[43m]\u001b[49m \n\u001b[0;32m     62\u001b[0m h_G \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobalGRU(t_r, h_P_previous ,h_G)\n\u001b[0;32m     63\u001b[0m h_G_all\u001b[38;5;241m.\u001b[39mappend(h_G)\n",
      "\u001b[1;31mIndexError\u001b[0m: Exception encountered when calling layer \"dialogue_rnn_11\" (type DialogueRNN).\n\nlist index out of range\n\nCall arguments received:\n  • messages=tf.Tensor(shape=(22, 8, 250), dtype=float32)\n  • speakers=tf.Tensor(shape=(22, 8, 2), dtype=float32)"
     ]
    }
   ],
   "source": [
    "def loss(model, messages, speakers, y):\n",
    "    loss_object = k.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    \n",
    "    y_pred_prob_all, y_pred_all = model(messages, speakers)\n",
    "    print(y_pred_all)\n",
    "    #y = np.transpose(y, (1, 0, 2))\n",
    "    result = loss_object(y_true=y, y_pred=y_pred_prob_all)\n",
    "    \n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "def grad(model, messages, speakers, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, messages, speakers, y)\n",
    "        #print([var.name for var in tape.watched_variables()])\n",
    "\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables\n",
    "                                     #unconnected_gradients=tf.UnconnectedGradients.ZERO\n",
    ")\n",
    "\n",
    "\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "#data1 = build_batch(dialogue_train_data, 1, 8)\n",
    "data2 = build_batch(dialogue_train_data, 2, batch_size)\n",
    "data3 = build_batch(dialogue_train_data, 3, batch_size)\n",
    "data4 = build_batch(dialogue_train_data, 4, batch_size)\n",
    "data = data2 + data3 + data4\n",
    "num_epochs = 10\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-06)\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "    # Training loop - using batches of 32\n",
    "    for (batch, (messages, speakers, y)) in enumerate(data):\n",
    "\n",
    "        #y_all = y_train[\"y_label\"]\n",
    "        print(\"For data lOADER\")\n",
    "        print(messages.shape)\n",
    "        print(speakers.shape)\n",
    "        loss_value, grads = grad(model, messages, speakers,  y)\n",
    "        #print(grads)\n",
    "        #print(\"Step: {}, Initial Loss: {}\".format(optimizer.iterations.numpy(),\n",
    "                                          #loss_value.numpy()))\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        #print(\"Step: {},         Loss: {}\".format(optimizer.iterations.numpy(),\n",
    "                                          #loss(model, messages, speakers, y).numpy()))\n",
    "        \n",
    "        # Track progress\n",
    "        epoch_loss_avg.update_state(loss_value)  # Add current batch loss\n",
    "        # Compare predicted label to actual label\n",
    "        # training=True is needed only if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        y_pred_prob_all, y_pred_all =  model( messages, speakers)\n",
    "        #epoch_accuracy.update_state(y_all, y_pred_all)\n",
    "\n",
    "    # End epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "    \n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                            epoch_loss_avg.result(),\n",
    "                                                            epoch_accuracy.result()))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f86ba558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_accuracy_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = tf.keras.metrics.Accuracy()\n",
    "ds_test_batch = ds_test.batch(10)\n",
    "\n",
    "for (x, y) in ds_test_batch:\n",
    "    # training=False is needed only if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    logits = model(x, training=False)\n",
    "    prediction = tf.argmax(logits, axis=1, output_type=tf.int64)\n",
    "    test_accuracy(prediction, y)\n",
    "\n",
    "print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
